trainer:
  name: lipizzaner_gan	#lipizzaner_gan, lipizzaner_wgan, backprop, sequential_nes, parallel_nes, alternatin_ea, parallel_ea
  n_iterations: 50
  calculate_net_weights_dist: True #doesn't seem to do anything
  mixture_generator_samples_mode: exact_proportion #independent_probability, exact_proportion
  evaluate_subpopulations_every: 1 #The frequency, a subpopulations' fitness is measured
  subpopulation_sample_size: None #
  params:
    population_size: 1 #initial population in a node 
    tournament_size: 2 
    n_replacements: 1	#replace n number of generators in a neighbourhood
    default_adam_learning_rate: 0.0002
    # Hyperparameter mutation 
    alpha: 0.0001	
    sigma: 0.25
    mutation_probability: 0.5
    discriminator_skip_each_nth_step: 1
    mixture_sigma: 0.01 #Mutation std
    enable_selection: True
    score:	#optional, optimizes score during training
      enabled: True #True, False
      type: fid #gaussian_toy_distances, fid, inception_score, constant
      score_sample_size: 200
      cuda: True
    optimize_mixture: #optional, optimizes weights at the end 
	#optimize_weights_at_the_end
	sample_size: 10000
	es_generations: 10 #evolutionary generations
	es_random_init: False
	mixture_sigma: 0.01 #overwrites previous mixture_sigma
    fitness:  #NOT optional, it must be configured
      fitness_sample_size: 200
      fitness_mode: average    # worse, best, average
	#fitness_batch_size: 64
dataloader:
  dataset_name: covidqu 
  use_batch: True
  batch_size: 100
  n_batches: 0 #used batches during iteration, if 0, use all batches
  shuffle: True
  sampling_ratio: 1 #the ratio of the dataset used
network:
  name: four_layer_perceptron
  loss: bceloss #bceloss, mseloss, heuristicloss, mustangs
master:
  calculate_score: True
  # Same amount of data as original CIFAR contains
  score_sample_size: 1000
  cuda: True #If true, score will be calculated on cuda 
general: !include general.yml