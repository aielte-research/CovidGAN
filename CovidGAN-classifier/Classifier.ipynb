{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing GAN generated data augmentation, using different proportions of data for training GAN \n",
    "## This was \n",
    "\n",
    "Dataset is COVID_QU_Ex dataset from Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import subprocess\n",
    "import time\n",
    "import neptune \n",
    "from sklearn.metrics  import ConfusionMatrixDisplay, confusion_matrix, accuracy_score, balanced_accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "#This code needs a little bit rework, so testing will be easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = 'CovidData/Lung_Segmentation_Data'\n",
    "#run = neptune.init_run()\n",
    "\n",
    "torch.set_num_threads(8)\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_directories = {\n",
    "    'Test_orig_0.8' : {'dir':'2023-03-14_19-00-08','best':'127.0.0.1-5002'},\n",
    "    'Test_orig_0.6' : {'dir':'2023-03-15_09-51-22','best':'127.0.0.1-5001'},\n",
    "    'Test_orig_0.4' : {'dir':'2023-03-16_17-23-13','best':'127.0.0.1-5002'},\n",
    "    'Test_orig_0.2' : {'dir':'2023-03-17_11-28-34','best':'127.0.0.1-5002'},\n",
    "    \n",
    "    'Test_0_0.8' : {'dir':'2023-03-23_15-19-22','best':'127.0.0.1-5002'},\n",
    "    'Test_0_0.6' : {'dir':'2023-03-24_16-23-49','best':'127.0.0.1-5001'},\n",
    "    'Test_0_0.4' : {'dir':'2023-03-25_09-50-59','best':'127.0.0.1-5001'},\n",
    "    'Test_0_0.2' : {'dir':'2023-03-25_16-58-45','best':'127.0.0.1-5003'},\n",
    "\n",
    "    'Test_1_0.8' : {'dir':'2023-03-21_16-13-32','best':'127.0.0.1-5003'},\n",
    "    'Test_1_0.6' : {'dir':'2023-03-22_09-56-24','best':'127.0.0.1-5001'},\n",
    "    'Test_1_0.4' : {'dir':'2023-03-22_18-38-27','best':'127.0.0.1-5000'},\n",
    "    'Test_1_0.2' : {'dir':'2023-03-23_08-16-51','best':'127.0.0.1:5002'},\n",
    "\n",
    "    'Test_2_0.8' : {'dir':'2023-03-19_18-20-08','best':'127.0.0.1-5001'},\n",
    "    'Test_2_0.6' : {'dir':'2023-03-20_08-46-21','best':'127.0.0.1-5001'},\n",
    "    'Test_2_0.4' : {'dir':'2023-03-20_16-58-27','best':'127.0.0.1-5001'},\n",
    "    'Test_2_0.2' : {'dir':'2023-03-21_08-49-59','best':'127.0.0.1-5002'},\n",
    "\n",
    "    'Test_3_0.8' : {'dir':'2023-03-17_17-42-29','best':'127.0.0.1-5001'},\n",
    "    'Test_3_0.6' : {'dir':'2023-03-18_07-56-44','best':'127.0.0.1-5003'},\n",
    "    'Test_3_0.4' : {'dir':'2023-03-18_23-01-23','best':'127.0.0.1-5002'},\n",
    "    'Test_3_0.2' : {'dir':'2023-03-19_07-43-42','best':'127.0.0.1-5000'},\n",
    "     }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_transform = torchvision.transforms.Compose([\n",
    "#    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#    torchvision.transforms.Grayscale(num_output_channels=1),\n",
    "#    torchvision.transforms.Resize(size=(128, 128)),\n",
    "#    torchvision.transforms.ToTensor()\n",
    "#])\n",
    "\n",
    "#test_transform = torchvision.transforms.Compose([\n",
    "#    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "#    torchvision.transforms.Grayscale(num_output_channels=1),\n",
    "#    torchvision.transforms.Resize(size=(128, 128)),\n",
    "#    torchvision.transforms.ToTensor()\n",
    "#])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomDataset(torchvision.datasets.ImageFolder):\n",
    "    \"\"\"\n",
    "        A simple imagedatset for storing data\n",
    "    \"\"\"\n",
    "    #Imagefolder for efficiency\n",
    "    def __init__(self, images, transform):\n",
    "        target_dir = os.path.join(ROOT_DIR, 'original')\n",
    "        super().__init__(target_dir, transform)\n",
    "        self.samples = images\n",
    "        self.imgs = images\n",
    "\n",
    "def DatasetMaker(split, mode=None, data_ratio=1, transform = None, geoaugment=False, seed = 0):\n",
    "    \"\"\"\n",
    "        Returns a CustomDataset with given parameters\n",
    "        split: str, determines train-test to use; options: 'orig', '0', '1', '2', '3'\n",
    "        mode: str, 'oversampling', 'gan' or None\n",
    "            'oversampling' : oversample with real images to balance classes\n",
    "                    'gan' : balance datasets with gan generated images (uses data_ratio to figure out which gan to use)\n",
    "                    None  : dataset won't be balanced\n",
    "        data_ratio (optional): int, the ratio of the training covid data to be used\n",
    "                    options:\n",
    "                        '1' : all data\n",
    "                        '0.8' : 80% of training images\n",
    "                        '0.6' : 60% of training images\n",
    "                        '0.4' : 40% of training images\n",
    "                        '0.2' : 20% of training images\n",
    "        transform (optional): torch.Compose instance, sets the dataset's transforms\n",
    "        geougment (optional): bool, uses basic data augmentation techmiques\n",
    "        seed (optional): int, seed to use for reproducibility\n",
    "    \"\"\"\n",
    "    #This code prepares my fixed set of images to replace the Imagefolder's original images\n",
    "    #Maybe this could be done nicer with overwriting the DatasetFolder's find_classes method, but currently this works\n",
    "    # the idea is to make (route, index) pairs for later loading in images\n",
    "    classes = ['normal', 'viral', 'covid']\n",
    "\n",
    "    #Determining the root directories for original images \n",
    "    orig_dirs = {\n",
    "    'normal' : f'{ROOT_DIR}/original/Normal',\n",
    "    'viral' : f'{ROOT_DIR}/original/Non-Covid',\n",
    "    'covid' : f'{ROOT_DIR}/original/COVID-19'\n",
    "    }\n",
    "    #Determining the root directories for generated images \n",
    "    fake_dirs = {\n",
    "        'gan_0.8' : f'{ROOT_DIR}/generated/Test_{split}/gan_0.8',\n",
    "        'gan_0.6' : f'{ROOT_DIR}/generated/Test_{split}/gan_0.6',\n",
    "        'gan_0.4' : f'{ROOT_DIR}/generated/Test_{split}/gan_0.4',\n",
    "        'gan_0.2' : f'{ROOT_DIR}/generated/Test_{split}/gan_0.2'\n",
    "    }\n",
    "    #Determining the root directories for files which contain the names of the COVID19 pictures \n",
    "    indicies_files = {\n",
    "        'gan_0.8' : f'{ROOT_DIR}/Indicies_files/Test_{split}/{split}_split_0.8_gan.pkl', \n",
    "        'gan_0.6' : f'{ROOT_DIR}/Indicies_files/Test_{split}/{split}_split_0.6_gan.pkl',\n",
    "        'gan_0.4' : f'{ROOT_DIR}/Indicies_files/Test_{split}/{split}_split_0.4_gan.pkl',\n",
    "        'gan_0.2' : f'{ROOT_DIR}/Indicies_files/Test_{split}/{split}_split_0.2_gan.pkl',\n",
    "        'test'  : f'{ROOT_DIR}/Indicies_files/Test_{split}/{split}_split_test.pkl',\n",
    "        'train'  : f'{ROOT_DIR}/Indicies_files/Test_{split}/{split}_split_train_and_val.pkl'\n",
    "    }\n",
    "    class_idx = {\n",
    "        'covid': 0, \n",
    "        'viral': 1,\n",
    "        'normal': 2,\n",
    "        'gan_0.8' : 0,\n",
    "        'gan_0.6' : 0,\n",
    "        'gan_0.4' : 0,\n",
    "        'gan_0.2' : 0\n",
    "    }\n",
    "    idx_to_class ={\n",
    "        0: 'covid',\n",
    "        1: 'viral',\n",
    "        2: 'normal'\n",
    "    }\n",
    "    valid_ratios = [1, 0.8, 0.6, 0.4, 0.2]\n",
    "\n",
    "    #The dictionary that will contain the route for the several image classes\n",
    "    source_dir = {}\n",
    "    train_images = []\n",
    "\n",
    "    #creating the sources for the classes\n",
    "    for class_name in classes: \n",
    "        source_dir[class_name] = orig_dirs[class_name]\n",
    "    \n",
    "    #Get all training images\n",
    "    file = indicies_files['train'] \n",
    "    imgs = load_images_from_file(file)\n",
    "    imgs = [*imgs[0],*imgs[1]] #The file contains (train, val) sets\n",
    "    \n",
    "    #Making the paths for the training images\n",
    "    #num_of_covid_imgs = 0 #?\n",
    "    for x in imgs: \n",
    "        class_of_x = idx_to_class[x[1]] #The images are saved in (image_name, class_index) format\n",
    "        item = os.path.join(source_dir[class_of_x],x[0]),class_idx[class_of_x] \n",
    "        #if item[1] == class_idx['covid']: num_of_covid_imgs +=1 #?\n",
    "        train_images.append(item)\n",
    "    #If data_ratio is not 1, we need to change the covid images of the dataset\n",
    "    if data_ratio!=1:\n",
    "        #num_of_covid_imgs = 0\n",
    "        train_images = [x for x in train_images if x[1]!=class_idx['covid']]\n",
    "        file = indicies_files[f'gan_{data_ratio}']\n",
    "        imgs = load_images_from_file(file)\n",
    "        for x in imgs:\n",
    "            class_of_x = idx_to_class[x[1]]\n",
    "            item = os.path.join(source_dir[class_of_x],x[0]),class_idx[class_of_x] \n",
    "            #if item[1] == class_idx['covid']: num_of_covid_imgs +=1 \n",
    "            train_images.append(item)\n",
    "    \n",
    "    #If picture generation is needed we want to know the average class size and missing number of covid images\n",
    "    #average_class_size = round((len(train_images)-num_of_covid_imgs)/2)\n",
    "    #missing_images = max(0, average_class_size - num_of_covid_imgs)\n",
    "\n",
    "    #Determining wether image generation is needed and which kind of it then making the generation\n",
    "    if mode=='gan' and (data_ratio in valid_ratios):\n",
    "        gan = f'gan_{data_ratio}'\n",
    "        gan_dir = fake_dirs[gan]\n",
    "        #generate_images_to_dir(split, data_ratio, gan, gan_dir, missing_images) #?\n",
    "        gan_ims = []\n",
    "        for x in os.listdir(gan_dir): #optimize further\n",
    "            if x.lower().endswith('jpg'):\n",
    "                item = os.path.join(gan_dir, x), class_idx['covid']\n",
    "                gan_ims.append(item)\n",
    "        sample = random.sample(gan_ims, missing_images)\n",
    "        train_images = [*train_images,*sample]\n",
    "    elif mode=='oversampling':\n",
    "        covid_images = [x for x in train_images if x[1]==class_idx['covid']]\n",
    "        batch_size = len(covid_images)\n",
    "        while batch_size <= missing_images:\n",
    "            train_images = [*train_images, *covid_images]\n",
    "            missing_images -= batch_size\n",
    "        if missing_images>0:\n",
    "            sample = random.sample(covid_images, missing_images)\n",
    "            train_images = [*train_images, *sample]\n",
    "    \n",
    "    #Making the paths for the test images\n",
    "    test_images = []\n",
    "    test_imgs = load_images_from_file(indicies_files['test'])\n",
    "    for x in test_imgs:\n",
    "        class_of_x = idx_to_class[x[1]]\n",
    "        item = os.path.join(source_dir[class_of_x],x[0]),class_idx[class_of_x] #This should be correct\n",
    "        test_images.append(item)\n",
    "    random.Random(seed).shuffle(test_images)\n",
    "    bound = len(test_images)//2\n",
    "    val_images = test_images[bound:]\n",
    "    test_images = test_images[:bound]\n",
    "    #Making some basic transforms \n",
    "    if transform is None:\n",
    "        transforms = [ torchvision.transforms.Resize(size=(128, 128)),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                    torchvision.transforms.Grayscale(num_output_channels=1)]\n",
    "    else:\n",
    "        transforms = transform\n",
    "\n",
    "    #Checking wether geometric augmentation is needed ( classic augmentation methods)\n",
    "    if geoaugment:\n",
    "        augmentation_transforms = [#torchvision.transforms.RandomHorizontalFlip(), #(should be useful, causes confusion with gans)\n",
    "                                torchvision.transforms.RandomAffine(4)]\n",
    "        transforms = [augmentation_transforms + transforms]                      \n",
    "    transforms = torchvision.transforms.Compose(transforms)\n",
    "    train_dataset = CustomDataset(train_images, transforms)\n",
    "    val_dataset = CustomDataset(val_images, transforms)\n",
    "    test_dataset = CustomDataset(test_images,  transforms)\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "def load_images_from_file(file):\n",
    "    with open(file, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data   \n",
    "    \n",
    "#def generate_images_to_dir(split, data_ratio, gan, directory, size):\n",
    "#    \"\"\"\n",
    "#        Generates pictures with a given gan, to a given directory\n",
    "#    \"\"\"\n",
    "#    #Goes into Lipizzaner's directory and then generates images with a given GAN (this function is a Lipizzaner built-in method)\n",
    "#    #Then returns into this directory\n",
    "#    \n",
    "#    curr_dir = os.getcwd()\n",
    "#    print(curr_dir)\n",
    "#    \n",
    "#    lippi_dir = '/home/bbernard/lipizzaner-covidgan-master/src/'  #Change this on server\n",
    "#    \n",
    "#    output_dir = os.path.join(curr_dir, directory) #?\n",
    "#   \n",
    "#   #Gan to use is determined by the split and the data_ratio parameters\n",
    "#    gan_dir = gan_directories[f'Test_{split}_{data_ratio}'] \n",
    "#    src_dir = os.path.join(lippi_dir, f'output/lipizzaner_gan/master/{gan_dir}/127.0.0.1-5000')\n",
    "#    \n",
    "#    config_file = os.path.join(lippi_dir, f'configuration/covid-qu-conv/Test_{split}/covidqu_{data_ratio}.yml')\n",
    "#    \n",
    "#    #man = os.path.join(lippi_dir, 'main.py')#\n",
    "#\n",
    "#    code =f'python main.py generate --mixture-source {src_dir} -o {output_dir} --sample-size {size} -f {config_file}'\n",
    "#    os.chdir(lippi_dir)\n",
    "#    subprocess.run(code, shell=True)\n",
    "#    os.chdir(curr_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(name):\n",
    "    \"\"\"\n",
    "        Returns pretrained models\n",
    "    \"\"\"\n",
    "    if name==\"resnet\":\n",
    "        resnet18 = torchvision.models.resnet18(pretrained=True)\n",
    "        resnet18.conv1= torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        resnet18.fc = torch.nn.Linear(in_features=512, out_features=3)\n",
    "        resnet18.get_name = 'resnet18'\n",
    "        return resnet18\n",
    "    elif name==\"vgg\":\n",
    "        vgg16 = torchvision.models.vgg16(pretrained=True)\n",
    "        vgg16.features[0] = torch.nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        vgg16.classifier[6] = torch.nn.Linear(in_features=4096, out_features=3, bias=True)\n",
    "        vgg16.get_name = 'vgg16'\n",
    "        return vgg16\n",
    "    elif name==\"efficient\":\n",
    "        efficient = torchvision.models.efficientnet_b0(pretrained=True)\n",
    "        efficient.features[0][0] = torch.nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        efficient.classifier[1] = torch.nn.Linear(in_features=1280, out_features=3, bias=True)\n",
    "        efficient.get_name = 'efficientnet_b0'\n",
    "        return efficient\n",
    "    else:\n",
    "        print(\"Not implemented\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making modell, loss function and optimizer\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(epochs, net, loss_fn, optimizer, train_dataset, test_dataset, batch_size, shuffle, neptune_run): #, neptune_run ):\n",
    "    \"\"\"\n",
    "        A simple train function \n",
    "        Params: \n",
    "            epoch: number of epochs to train for\n",
    "            modell: The neural network to train\n",
    "            loss_fn: Loss function instance\n",
    "            optimizer: optimizer instance\n",
    "            train_dataset (Dataset)\n",
    "            test_dataset (Dataset)\n",
    "            batch_size (int)\n",
    "            shuffle (bool) \n",
    "    \"\"\"\n",
    "\n",
    "    train_dl = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, num_workers=0, shuffle= shuffle)\n",
    "    test_dl =  torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, num_workers=0, shuffle= shuffle)\n",
    "\n",
    "    #Logging history\n",
    "    #history = {'train_loss': [],\n",
    "    #           'train_accuracy': [],\n",
    "    #           'val_loss': [],\n",
    "    #           'val_accuracy': [],\n",
    "    #           'conf_matrix': [],\n",
    "    #           'acc' : [],\n",
    "    #           'bal_acc' : [], \n",
    "    #           'recall' : [], \n",
    "    #           'precision' : [], \n",
    "    #           'f1':[]\n",
    "    #           }\n",
    "\n",
    "    print('Starting training..')\n",
    "    for e in range(epochs):\n",
    "        print('='*20)\n",
    "        print(f'Starting epoch {e + 1}/{epochs}')\n",
    "        print('='*20)\n",
    "\n",
    "        train_iter = iter(train_dl)\n",
    "        \n",
    "        train_accuracy = 0.\n",
    "        train_loss = 0.\n",
    "        \n",
    "        sample_num = 0 \n",
    "\n",
    "        net.train() #set model to training phase\n",
    "        \n",
    "        #Training \n",
    "        batch_num = 0\n",
    "        while batch_num< len(train_dl):\n",
    "            images, labels = next(train_iter)\n",
    "           \n",
    "            images = images.to(device) \n",
    "            labels = labels.to(device) \n",
    "            \n",
    "            outputs = net(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #train_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            sample_num += len(labels)\n",
    "            train_accuracy += sum((preds == labels).cpu().numpy())/len(labels)\n",
    "            train_loss += loss.item()/len(labels) #average loss throughout the batch\n",
    "            batch_num += 1\n",
    "            \n",
    "        train_loss/= len(train_dl)\n",
    "        train_accuracy/= len(train_dataset)\n",
    "        print(f'Train step: {batch_num} Training Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}')\n",
    "        neptune_run['train/train_loss'].append(train_loss)\n",
    "        neptune_run['train/train_accuracy'].append(train_accuracy)\n",
    "\n",
    "        val_loss = 0.\n",
    "        val_accuracy = 0.\n",
    "\n",
    "        val_batch_num = 0\n",
    "        val_iter = iter(test_dl)\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        net.eval()\n",
    "        while val_batch_num < len(val_iter):\n",
    "            images, labels = next(val_iter)\n",
    "            y_true.extend(images)\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            y_pred.extend(preds.detach().cpu())\n",
    "            val_accuracy += sum((preds == labels).cpu().numpy())\n",
    "            val_batch_num += 1\n",
    "\n",
    "        val_loss /= len(test_dl)\n",
    "        val_accuracy = val_accuracy/len(test_dataset)\n",
    "        print(f'Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "        net.train()\n",
    "\n",
    "        neptune_run['train/val_loss'].append(val_loss)\n",
    "        neptune_run['train/val_accuracy'].append(val_accuracy)\n",
    "\n",
    "        curr_conf_matrix = confusion_matrix(y_true, y_pred) \n",
    "        curr_conf_matrix = curr_conf_matrix / np.sum(curr_conf_matrix)\n",
    "        im = ConfusionMatrixDisplay(curr_conf_matrix, display_labels=[\"fake\", \"real\"]).plot()\n",
    "        neptune_run['metrics/conf_matrix'].append(im.figure_) #, description=f\"Confusion matrix in the iteration: {iteration}\"  File.as_image(curr_conf_matrix))\n",
    "        neptune_run['metrics/acc'].append( accuracy_score(y_true, y_pred))\n",
    "        neptune_run['metrics/bal_acc'].append(balanced_accuracy_score(y_true, y_pred))\n",
    "        neptune_run['metrics/recall'].append(recall_score(y_true, y_pred))\n",
    "        neptune_run['metrics/precision'].append( precision_score(y_true, y_pred))\n",
    "        neptune_run['metrics/f1'].append( f1_score(y_true, y_pred))    \n",
    "        #neptune_run['val/loss'].append(val_loss)\n",
    "        #neptune_run['val/accuracy'].append(val_accuracy)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    print('Training complete..')\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_history(network, case_string): #,history\n",
    "    \"\"\"\n",
    "        A simple function that saves the histories and the clasificator net\n",
    "    \"\"\"\n",
    "    FILEBASE = f\"Histories/{case_string}\"\n",
    "    torch.save(network.state_dict(), FILEBASE + '.pt')\n",
    "    #with open(FILEBASE + '-history.pkl', 'wb') as file:\n",
    "    #    pickle.dump(history, file)\n",
    "    #    print(f'{FILEBASE} instance saved')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "'split' : 'orig',\n",
    "'data_ratio' : 1,   #1, 0.8, 0.6, 0.4, 0.2\n",
    "'augment' : None,       #gan, oversampling, None\n",
    "'geoaugment': False,\n",
    "'batch_size' : 128,\n",
    "'epochs' : 3, #30/40\n",
    "'network_name' : \"resnet\", #resnet, vgg, efficient\n",
    "'optimizer' : \"adam\",\n",
    "'adam_lr' : 3e-5,\n",
    "'loss_function' : \"CrossEntropyLoss\",\n",
    "'id': time.strftime(\"%H-%M-%S\")\n",
    "}\n",
    "\n",
    "network = get_model(params['network_name'])\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=params['adam_lr'])\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_dataset, test_dataset = DatasetMaker(params['split'],params['augment'], params['data_ratio'])\n",
    "\n",
    "neptune_run = neptune.init_run()\n",
    "neptune_run['params'] = params\n",
    "net = train(params['epochs'], network, loss_fn, optimizer, \n",
    "                train_dataset, test_dataset, params['batch_size'],suffle = True, geoaugment = params['geoaugment'], shuffle=True, neptune_run = neptune_run)\n",
    "neptune_run.stop()\n",
    "\n",
    "case_string = f\"{params['network_name']}_{params['split']}_{params['ratio']}_{params['augment']}_{params['geoaugment']}_{params['id']}\"\n",
    "save_history(net, case_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if __name__=='__main__':\n",
    "#    splits = ['orig','0','1', '2','3']\n",
    "##\n",
    "#    for split in splits:\n",
    "#        #simple tests when no augmentation is done\n",
    "#        Test_with_all_ratios(split = split, epochs = 1, network_name='resnet', mode = None, geoaugment=False)\n",
    "#        Test_with_all_ratios(split = split, epochs = 1, network_name='vgg', mode = None, geoaugment=False)\n",
    "#        Test_with_all_ratios(split = split, epochs = 1, network_name='efficient', mode = None, geoaugment=False)\n",
    "#\n",
    "#\n",
    "#        #simple tests when oversasmpling is used to balance classes\n",
    "#        Test_with_all_ratios(split = split, epochs = 1, network_name='resnet', mode = 'oversampling', geoaugment=False)\n",
    "#        Test_with_all_ratios(split = split, epochs = 1, network_name='vgg', mode = 'oversampling', geoaugment=False)\n",
    "#        Test_with_all_ratios(split = split, epochs = 1, network_name='efficient', mode = 'oversampling', geoaugment=False)#\n",
    "#\n",
    "#        #simple tests when gan is used to balance classes\n",
    "#        Test_with_all_ratios(split = split, epochs = 1,  network_name='resnet', mode = 'gan', geoaugment=False)\n",
    "#        Test_with_all_ratios(split = split, epochs = 1, network_name='vgg', mode = 'gan', geoaugment=False)\n",
    "#        Test_with_all_ratios(split = split, epochs = 1, network_name='efficient', mode = 'gan', geoaugment=False)\n",
    "#\n",
    "#        #simple Test when just geoaugmentation is used\n",
    "#        #Test_with_all_ratios(split = split, epochs = 1, network_name='resnet', mode = None, geoaugment=True)\n",
    "#        #Test_with_all_ratios(split = split, epochs = 1, network_name='vgg', mode = None, geoaugment=True)\n",
    "#        #Test_with_all_ratios(split = split, epochs = 1, network_name='efficient', mode = None, geoaugment=True)#\n",
    "#\n",
    "#        #simple tests when oversasmpling is used to balance classes and geoaugment\n",
    "#        #Test_with_all_ratios(split = split, epochs = 1, network_name='resnet', mode = 'oversampling', geoaugment=True)\n",
    "#        #Test_with_all_ratios(split = split, epochs = 1, network_name='vgg', mode = 'oversampling', geoaugment=True)\n",
    "#        #Test_with_all_ratios(split = split, epochs = 1, network_name='efficient', mode = 'oversampling', geoaugment=True)\n",
    "#\n",
    "#        #simple tests when gan is used to balance classes and geoaugment\n",
    "#        #Test_with_all_ratios(split = split, epochs = 1, network_name='resnet', mode = 'gan', geoaugment=True)\n",
    "#        #Test_with_all_ratios(split = split, epochs = 1, network_name='vgg', mode = 'gan', geoaugment=True)\n",
    "#        #Test_with_all_ratios(split = split, epochs = 1, network_name='efficient', mode = 'gan', geoaugment=True)\n",
    "#    \n",
    "#    print(\"All training is done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bcb96da45b2fc45e59405d102e32af3d42527a73937a6435f97ad1b01889c6a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
