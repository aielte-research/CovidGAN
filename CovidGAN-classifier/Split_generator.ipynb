{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code:\n",
    "####   1. Loads in all the pictures from the COVID_QU_EX dataset\n",
    "####   2. Makes five train_test split \n",
    "####   3. Saves the train-test splits to unique files (pkl)\n",
    "####   4. For each split, filters out the covid images of the train set\n",
    "####   5. For the covid images makes subsplits keeping the [0.8, 0.6, 0.4, 0.2] ratios of the covid images \n",
    "####   6. Saves all ratio-split variaton of covid images to unique files (pkl)\n",
    "##### Note: The covid images are used in training Generator Adversarial Networks and the train-test datasets are used in classification \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making class-index pairs\n",
    "classes = ['COVID-19', 'Non-COVID', 'Normal']\n",
    "class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "\n",
    "def get_images_from_folder(folder):\n",
    "    #Gets a folder: Train, Val or Test, returns all images in the folders (COVID19, Non-COVID and Normal)\n",
    "    instances = []\n",
    "    for clas in classes:\n",
    "        class_path = os.path.join(folder, clas, 'images')\n",
    "        class_index = class_to_idx[clas]\n",
    "        for root, _, fnames in sorted(os.walk(class_path, followlinks=True)):\n",
    "            for fname in sorted(fnames):\n",
    "                #path = os.path.join(root, fname)\n",
    "                item = fname, class_index\n",
    "                instances.append(item)\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21715\n",
      "6788\n",
      "5417\n",
      "0.20011792452830188\n",
      "0.15969929245283018\n",
      "0.6401827830188679\n"
     ]
    }
   ],
   "source": [
    "#This code will create 5 train-test splits from the original COVID-Qu-Ex dataset \n",
    "#The first split is the original, given by the authors of the dataset (The original cut was \n",
    "#implemented for a reason)\n",
    "folders = {\n",
    "    'train' : '.\\Image_sets\\Train',\n",
    "    'val' : '.\\Image_sets\\Val',\n",
    "    'test' : '.\\Image_sets\\Test'\n",
    "}\n",
    "\n",
    "train_set = get_images_from_folder(folders['train'])\n",
    "test_set = get_images_from_folder(folders['test'])\n",
    "val_set = get_images_from_folder(folders['val'])\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "print(len(val_set))\n",
    "print(len(test_set) / (len(train_set) + len(val_set) + len(test_set)) ) #test set is 20%\n",
    "print(len(val_set) / (len(train_set) + len(val_set) + len(test_set)) ) #val set is 16%\n",
    "print(len(train_set) / (len(train_set) + len(val_set) + len(test_set)) ) #test set is 64%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump test_set, train_set and val_set to train.pkl, test.pkl, val.pkl with pickle\n",
    "def save_sets(train_set, val_set, test_set, split):\n",
    "    dump_obj1 = (train_set, val_set)\n",
    "    dump_obj2 = test_set\n",
    "\n",
    "    with open(f'{split}_split_train_and_val.pkl', 'wb') as file:\n",
    "        pickle.dump(dump_obj1, file)\n",
    "        \n",
    "    with open(f'{split}_split_test.pkl', 'wb') as file:\n",
    "        pickle.dump(dump_obj2, file)\n",
    "\n",
    "def check_ratio(train, test, val):\n",
    "    #Making sure that in each train-test splits the ratio of the classes of the images are roughly the same\n",
    "    ls = [train, test, val]\n",
    "    for set in ls:\n",
    "        classes = [0,0,0]\n",
    "        for image in set:\n",
    "            classes[image[1]] +=1\n",
    "        for i in range(len(classes)):\n",
    "            print(f'The ratio of the {i} class is {classes[i]/sum(classes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with saving sets, now saving covid pictures for gan\n",
      "Done with saving gans\n",
      "Done with saving sets, now saving covid pictures for gan\n",
      "Done with saving gans\n",
      "Done with saving sets, now saving covid pictures for gan\n",
      "Done with saving gans\n",
      "Done with saving sets, now saving covid pictures for gan\n",
      "Done with saving gans\n"
     ]
    }
   ],
   "source": [
    "save_sets(train_set, val_set, test_set, 'orig') #The first split is the original one from COVID_QU_EX database\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "all = [*train_set, *val_set, *test_set]\n",
    "for i in range(4):\n",
    "    trainey, test = train_test_split(all, test_size=0.2, random_state=42+i)\n",
    "    val_size = 0.16*(5/4) #should be 16% of all data\n",
    "    train, val = train_test_split(trainey, test_size=val_size, random_state=420+2*i)\n",
    "    save_sets(train_set, val_set, test_set, str(i))\n",
    "    #Furhtermore, we need gan_subsets for all splits, with 1, 0.8, 0.6, 0.4, 0.2 ratio of the train-val set\n",
    "    # We need only COVID-19 pictures\n",
    "    covid = [x for x in trainey if x[1] == class_to_idx['COVID-19']]\n",
    "    ratios = [0.8, 0.6, 0.4, 0.2]\n",
    "    with open(f'{i}_split_{1}_gan.pkl', 'wb') as file:\n",
    "        pickle.dump(covid, file)\n",
    "    for ratio in ratios:\n",
    "        _, gan = train_test_split(covid, test_size=ratio, random_state=420+3*i)\n",
    "        with open(f'{i}_split_{ratio}_gan.pkl', 'wb') as file:\n",
    "            pickle.dump(gan, file)\n",
    "    print(\"Done with saving gans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27132\n"
     ]
    }
   ],
   "source": [
    "#Making the split-ratio subsets for the original dataset split\n",
    "data = [*train_set, *val_set]\n",
    "covid = [x for x in data if x[1] == class_to_idx['COVID-19']]\n",
    "with open(f'orig_split_{1}_gan.pkl', 'wb') as file:\n",
    "        pickle.dump(covid, file)\n",
    "for ratio in ratios:\n",
    "    _, gan = train_test_split(covid, test_size=ratio, random_state=420+3*i)\n",
    "    with open(f'orig_split_{ratio}_gan.pkl', 'wb') as file:\n",
    "        pickle.dump(gan, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6aeca87e53583627b8b79e4f4da41d10e1acf8a2564923b7f23db1af83b45f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
